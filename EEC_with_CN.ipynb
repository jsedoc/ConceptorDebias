{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EEC with CN",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jsedoc/ConceptorDebias/blob/master/EEC_with_CN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "WQJS8yEwygVb",
        "colab_type": "code",
        "outputId": "2112a50d-b09d-49a9-9a47-7ba14e76bdbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "!wget http://www.saifmohammad.com/WebDocs/EEC/Equity-Evaluation-Corpus.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-17 19:25:14--  http://www.saifmohammad.com/WebDocs/EEC/Equity-Evaluation-Corpus.zip\n",
            "Resolving www.saifmohammad.com (www.saifmohammad.com)... 192.185.17.122\n",
            "Connecting to www.saifmohammad.com (www.saifmohammad.com)|192.185.17.122|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 102568 (100K) [application/zip]\n",
            "Saving to: ‘Equity-Evaluation-Corpus.zip’\n",
            "\n",
            "Equity-Evaluation-C 100%[===================>] 100.16K   575KB/s    in 0.2s    \n",
            "\n",
            "2019-02-17 19:25:14 (575 KB/s) - ‘Equity-Evaluation-Corpus.zip’ saved [102568/102568]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Le67qqg0ypdn",
        "colab_type": "code",
        "outputId": "fe434e61-1a53-45d2-b6a8-3385cbc2391f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip Equity-Evaluation-Corpus.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  Equity-Evaluation-Corpus.zip\n",
            "  inflating: Equity-Evaluation-Corpus.csv  \n",
            "  inflating: README.txt              \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LdMrdkW5ypSC",
        "colab_type": "code",
        "outputId": "beb2fc5b-2cf7-4222-b913-050ca3c55c60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy, requests, codecs, os, re, nltk, itertools, csv\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
        "import tensorflow as tf\n",
        "from scipy.stats import spearmanr\n",
        "import pandas as pd\n",
        "import functools as ft\n",
        "import os\n",
        "import io\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "07NMbgS0y5ji",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "EEC = pd.read_csv('/content/Equity-Evaluation-Corpus.csv', header=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zHGlOXkfzHYL",
        "colab_type": "code",
        "outputId": "e214976b-05f0-49e4-e422-7df4d9f8cd8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        }
      },
      "cell_type": "code",
      "source": [
        "print(EEC[:][0:5])\n"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                      ID                 Sentence  \\\n",
            "0  2018-En-mystery-05498      Alonzo feels angry.   \n",
            "1  2018-En-mystery-11722    Alonzo feels furious.   \n",
            "2  2018-En-mystery-11364  Alonzo feels irritated.   \n",
            "3  2018-En-mystery-14320    Alonzo feels enraged.   \n",
            "4  2018-En-mystery-14114    Alonzo feels annoyed.   \n",
            "\n",
            "                                 Template  Person Gender              Race  \\\n",
            "0  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
            "1  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
            "2  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
            "3  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
            "4  <person subject> feels <emotion word>.  Alonzo   male  African-American   \n",
            "\n",
            "  Emotion Emotion word  \n",
            "0   anger        angry  \n",
            "1   anger      furious  \n",
            "2   anger    irritated  \n",
            "3   anger      enraged  \n",
            "4   anger      annoyed  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7PipGcPqDAsp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load GloVe embeddings"
      ]
    },
    {
      "metadata": {
        "id": "EaIytYquTinV",
        "colab_type": "code",
        "outputId": "5b039b53-91cb-44ce-ee78-3db952fad5a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -q gdown\n",
        "!gdown https://drive.google.com/uc?id=1Ty2exMyi-XOufY-v81RJfiPvnintHuy2"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Ty2exMyi-XOufY-v81RJfiPvnintHuy2\n",
            "To: /content/gensim_glove.840B.300d.txt.bin\n",
            "2.65GB [00:47, 55.9MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "iERp98e_DE0T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Word2vec embeddings\n",
        "CN performed better using word2vec embeddings. For all 4 sentiments, CN showed improvements on debiasing gender bias.\n",
        "If using GloVe embeddings, CN showed improvements on anger, fear and joy. For the sentiment 'sadness', CN gave a higher gender difference. However, by my observations, results can be improved if using more female and male names to find conceptors. So with a larger name datasets, the results of 'sadness' may also show improvements on debiasing."
      ]
    },
    {
      "metadata": {
        "id": "89VbGhaRywxU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "53ccfb6d-77f9-4b38-9cd6-b6f43dd4831a"
      },
      "cell_type": "code",
      "source": [
        "!gdown https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
            "To: /content/GoogleNews-vectors-negative300.bin.gz\n",
            "1.65GB [00:11, 141MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ilnFmeJ22HSL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!gunzip /content/GoogleNews-vectors-negative300.bin.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s7NSiKG2DN2J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load male and female name lists"
      ]
    },
    {
      "metadata": {
        "id": "cIyTozuW3V2H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "653846b9-3cff-45eb-d19d-849780ce440a"
      },
      "cell_type": "code",
      "source": [
        "!wget https://www.cs.cmu.edu/Groups/AI/areas/nlp/corpora/names/male.txt\n",
        "!wget https://www.cs.cmu.edu/Groups/AI/areas/nlp/corpora/names/female.txt"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-02-17 19:40:51--  https://www.cs.cmu.edu/Groups/AI/areas/nlp/corpora/names/male.txt\n",
            "Resolving www.cs.cmu.edu (www.cs.cmu.edu)... 128.2.42.95\n",
            "Connecting to www.cs.cmu.edu (www.cs.cmu.edu)|128.2.42.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20466 (20K) [text/plain]\n",
            "Saving to: ‘male.txt’\n",
            "\n",
            "male.txt            100%[===================>]  19.99K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2019-02-17 19:40:52 (266 KB/s) - ‘male.txt’ saved [20466/20466]\n",
            "\n",
            "--2019-02-17 19:40:52--  https://www.cs.cmu.edu/Groups/AI/areas/nlp/corpora/names/female.txt\n",
            "Resolving www.cs.cmu.edu (www.cs.cmu.edu)... 128.2.42.95\n",
            "Connecting to www.cs.cmu.edu (www.cs.cmu.edu)|128.2.42.95|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 35751 (35K) [text/plain]\n",
            "Saving to: ‘female.txt’\n",
            "\n",
            "female.txt          100%[===================>]  34.91K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2019-02-17 19:40:53 (467 KB/s) - ‘female.txt’ saved [35751/35751]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "IhHsbJyNWgWb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "\n",
        "from gensim.models.keyedvectors import KeyedVectors\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LC3JKbM1Xmkx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "glove = KeyedVectors.load_word2vec_format('/content/' + 'gensim_glove.840B.300d.txt.bin', binary=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DeCv7ip13uN6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word2vec = KeyedVectors.load_word2vec_format('/content/' + 'GoogleNews-vectors-negative300.bin', binary=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PXx6x2vGEshx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Get frequency list (used in calculating sentence embeddings)"
      ]
    },
    {
      "metadata": {
        "id": "MWwGFIWGXqU7",
        "colab_type": "code",
        "outputId": "232b5115-8dd7-438b-c24f-7905285e8e42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/PrincetonML/SIF"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'SIF'...\n",
            "remote: Enumerating objects: 128, done.\u001b[K\n",
            "remote: Total 128 (delta 0), reused 0 (delta 0), pack-reused 128\u001b[K\n",
            "Receiving objects: 100% (128/128), 2.80 MiB | 6.92 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NRf-8VO3X0y7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "wikiWordsPath = '/content' + '/SIF/auxiliary_data/enwiki_vocab_min200.txt' # https://github.com/PrincetonML/SIF/blob/master/auxiliary_data/enwiki_vocab_min200.txt\n",
        "\n",
        "frequencies = {}\n",
        "with open(wikiWordsPath, \"r+\") as f_in:\n",
        "    for line in f_in:\n",
        "        frequencies[line.split(' ')[0]] = float(line.split(' ')[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TWXuqqFmE1_Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load gender names"
      ]
    },
    {
      "metadata": {
        "id": "Rog_F2625pyG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#load names from larger name dataset\n",
        "f = open('/content/male.txt', 'r+')\n",
        "i = 0\n",
        "word_list= []\n",
        "for line in f:\n",
        "  i+=1\n",
        "  if i < 7:\n",
        "    continue\n",
        "  token = line.split()\n",
        "  word_list.append(token[0])\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D75vc0Q86cIU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#load names from larger name dataset\n",
        "f = open('/content/female.txt', 'r+')\n",
        "i = 0\n",
        "for line in f:\n",
        "  i+=1\n",
        "  if i < 7:\n",
        "    continue\n",
        "  token = line.split()\n",
        "  word_list.append(token[0])\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a1pLLoV-6gSv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "32c49d45-6f73-4616-f60e-808a991fbbe9"
      },
      "cell_type": "code",
      "source": [
        "len(word_list)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7944"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "aVKauBMi6gJE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HjvwEWHd6wmQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For GloVe data\n",
        "cn_embeddings = []\n",
        "cn_embeddings.append([glove[word] for word in word_list if word in glove.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vNW92mNQ_B_X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For word2vec data\n",
        "cn_embeddings = []\n",
        "cn_embeddings.append([word2vec[word] for word in word_list if word in word2vec.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_JXi_dnD7EkN",
        "colab_type": "code",
        "outputId": "56da7877-bd83-43b5-f70b-5233f3bf4743",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "cn_embeddings.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7099, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "-wU25Uq1vdUv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Sentence embeddings"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6iZFRcuzwmZ6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "class Sentence:\n",
        "    \n",
        "    def __init__(self, sentence):\n",
        "        self.raw = sentence\n",
        "        normalized_sentence = sentence.replace(\"‘\", \"'\").replace(\"’\", \"'\")\n",
        "        self.tokens = [t.lower() for t in nltk.word_tokenize(normalized_sentence)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Itl-QRYavh9n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Raw Sentence Embeddings\n",
        "from sklearn.decomposition import TruncatedSVD, randomized_svd\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def run_sif_benchmark(sentiment, sent1, sent2, model_str, freqs={}, a=0.001): \n",
        "    total_freq = sum(freqs.values())\n",
        "    model = eval(model_str)\n",
        "    embeddings = []\n",
        "    \n",
        "        \n",
        "    tokens1 =  sent1.tokens\n",
        "    tokens2 =  sent2.tokens\n",
        "        \n",
        "    tokens1 = [token for token in tokens1 if token in model and token.islower()]\n",
        "    tokens2 = [token for token in tokens2 if token in model and token.islower()]\n",
        "        \n",
        "    weights1 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens1]\n",
        "    weights2 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens2]\n",
        "        \n",
        "    embedding1 = np.array(np.average([model[token] for token in tokens1], axis=0, weights=weights1))\n",
        "    embedding1 /= norm(embedding1)\n",
        "    embedding2 = np.array(np.average([model[token] for token in tokens2], axis=0, weights=weights2))\n",
        "    embedding2/= norm(embedding2)\n",
        "    proj1 = embedding1.dot(model[sentiment])/norm(model[sentiment])\n",
        "    proj2 = embedding2.dot(model[sentiment])/norm(model[sentiment])\n",
        "\n",
        "\n",
        "    return proj1, proj2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m6KBvMZJGRGt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#CN Sentence Embeddings\n",
        "def run_conceptor_benchmark(sentiment,sent1, sent2, model_str, freqs={}, a=0.001, alpha = 1): \n",
        "    total_freq = sum(freqs.values())\n",
        "    \n",
        "    model = eval(model_str)\n",
        "    embeddings = []\n",
        "    \n",
        "    # SIF requires us to first collect all sentence embeddings and then perform \n",
        "    # common component analysis.\n",
        "        \n",
        "    tokens1 =  sent1.tokens\n",
        "    tokens2 =  sent2.tokens\n",
        "        \n",
        "    tokens1 = [token for token in tokens1 if token in model and token.islower()]\n",
        "    tokens2 = [token for token in tokens2 if token in model and token.islower()]\n",
        "        \n",
        "    weights1 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens1]\n",
        "    weights2 = [a/(a+freqs.get(token,0)/total_freq) for token in tokens2]\n",
        "        \n",
        "    embedding1 = np.average([model[token] for token in tokens1], axis=0, weights=weights1)\n",
        "    embedding2 = np.average([model[token] for token in tokens2], axis=0, weights=weights2)\n",
        "        \n",
        "\n",
        "    R = (cn_embeddings.T).dot(cn_embeddings) / cn_embeddings.shape[0]\n",
        "\n",
        "    \n",
        "    \n",
        "    C = R @ np.linalg.inv (R + alpha ** (-1) * np.eye(300))# calculate the conceptor matrix\n",
        "    \n",
        "    negC = np.eye(300) - C\n",
        "    #negC = np.eye(300) - SWC[model_str]\n",
        "    \n",
        "    \n",
        "    embedding1 = negC.dot(embedding1.T).T\n",
        "    embedding2 = negC.dot(embedding2.T).T\n",
        "    embedding1 /= norm(embedding1)\n",
        "    embedding2 /= norm(embedding2)\n",
        "    proj1 = embedding1.dot(model[sentiment])/norm(model[sentiment])\n",
        "    proj2 = embedding2.dot(model[sentiment])/norm(model[sentiment])\n",
        "    return proj1, proj2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gtceGUSqxVPt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "dd5f00b0-047a-43ea-8f17-f68b3386165d"
      },
      "cell_type": "code",
      "source": [
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  male = []\n",
        "  female = []\n",
        "  fe_cn = []\n",
        "  ma_cn = []\n",
        "  sent_sent = []\n",
        "  sent_male = []\n",
        "  sent_female = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_male = sent_sent[sent_sent['Gender']=='male']\n",
        "  sent_female = sent_sent[sent_sent['Gender']=='female']\n",
        "  for sen1, sen2 in zip(sent_male['Sentence'], sent_female['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_sif_benchmark(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor_benchmark(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001)\n",
        "    male.append(score1)\n",
        "    female.append(score2)\n",
        "    ma_cn.append(score3)\n",
        "    fe_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(male, female)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(ma_cn, fe_cn)\n",
        "  print('gender difference on Raw and CN data:')\n",
        "  print(abs((sum(male)-sum(female))/len(male)), abs((sum(ma_cn)-sum(fe_cn))/len(ma_cn)))\n",
        "  print('t value and p value :')\n",
        "  print(p1,p2)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gender difference on Raw and CN data:\n",
            "0.005767845093150321 0.005397580093968621\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=6.317059235345078, pvalue=3.932023561199861e-10) Ttest_relResult(statistic=6.015496550869286, pvalue=2.4742236446720276e-09)\n",
            "gender difference on Raw and CN data:\n",
            "0.003845739790785252 0.0026864961281708455\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=3.522711132825228, pvalue=0.0004455470054571738) Ttest_relResult(statistic=2.4679085380428907, pvalue=0.013749174692869313)\n",
            "gender difference on Raw and CN data:\n",
            "0.0033155161928647473 0.001240718769312956\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-4.8701428744736965, pvalue=1.2867202888949841e-06) Ttest_relResult(statistic=-1.8027010202187714, pvalue=0.07172210067576126)\n",
            "gender difference on Raw and CN data:\n",
            "0.005565242321335648 0.004105681195314576\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-7.555460927719204, pvalue=9.067142764405745e-14) Ttest_relResult(statistic=-5.5222114276820715, pvalue=4.2198579924471897e-08)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "34-TlO--C0QR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Add extra names and pronouns\n",
        "#load names and pronouns from EEC\n",
        "name_pron = list(set(EEC['Person']))\n",
        "for item in name_pron:\n",
        "  num = item.rstrip().split(' ')\n",
        "  if len(num)!=1:\n",
        "    word_list.append(num[1])\n",
        "  else:\n",
        "    word_list.append(num[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M-FdCUanC7mh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cb63a24c-5f26-4675-9380-ae287338dcc6"
      },
      "cell_type": "code",
      "source": [
        "len(word_list)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8006"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "shWbzDiwDVvp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cn_embeddings = []\n",
        "cn_embeddings.append([word2vec[word] for word in word_list if word in word2vec.vocab])\n",
        "cn_embeddings = np.array(cn_embeddings[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PavqP7YWCsHG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "b272d634-dfc8-4a2f-89f6-e57af9c90c51"
      },
      "cell_type": "code",
      "source": [
        "for sen in ['anger','fear','joy', 'sadness']:\n",
        "  male = []\n",
        "  female = []\n",
        "  fe_cn = []\n",
        "  ma_cn = []\n",
        "  sent_sent = []\n",
        "  sent_male = []\n",
        "  sent_female = []\n",
        "  sent_sent = EEC[EEC['Emotion']==sen]\n",
        "  sent_male = sent_sent[sent_sent['Gender']=='male']\n",
        "  sent_female = sent_sent[sent_sent['Gender']=='female']\n",
        "  for sen1, sen2 in zip(sent_male['Sentence'], sent_female['Sentence']):\n",
        "    sentence1=Sentence(sen1)\n",
        "    sentence2=Sentence(sen2)\n",
        "    score1, score2 = run_sif_benchmark(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001)\n",
        "    score3, score4 = run_conceptor_benchmark(sen, sentence1, sentence2, 'word2vec', frequencies, 0.0001)\n",
        "    male.append(score1)\n",
        "    female.append(score2)\n",
        "    ma_cn.append(score3)\n",
        "    fe_cn.append(score4)\n",
        "  p1 = scipy.stats.ttest_rel(male, female)\n",
        "  #difference is significant, we can reject the null hypothesis that they are identical\n",
        "  p2 = scipy.stats.ttest_rel(ma_cn, fe_cn)\n",
        "  print('gender difference on Raw and CN data:')\n",
        "  print(abs((sum(male)-sum(female))/len(male)), abs((sum(ma_cn)-sum(fe_cn))/len(ma_cn)))\n",
        "  print('t value and p value :')\n",
        "  print(p1,p2)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gender difference on Raw and CN data:\n",
            "0.005767845093150321 0.005399172765531126\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=6.317059235345078, pvalue=3.932023561199861e-10) Ttest_relResult(statistic=6.0136036416959255, pvalue=2.5023267671744237e-09)\n",
            "gender difference on Raw and CN data:\n",
            "0.003845739790785252 0.0026753408966992864\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=3.522711132825228, pvalue=0.0004455470054571738) Ttest_relResult(statistic=2.456341871463754, pvalue=0.01419713023643722)\n",
            "gender difference on Raw and CN data:\n",
            "0.0033155161928647473 0.0012356795903471743\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-4.8701428744736965, pvalue=1.2867202888949841e-06) Ttest_relResult(statistic=-1.7951682001492033, pvalue=0.0729146733233671)\n",
            "gender difference on Raw and CN data:\n",
            "0.005565242321335648 0.004108918062410761\n",
            "t value and p value :\n",
            "Ttest_relResult(statistic=-7.555460927719204, pvalue=9.067142764405745e-14) Ttest_relResult(statistic=-5.525742201489073, pvalue=4.1382129084088664e-08)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MLYZ68Q6vXwP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}